% !TeX spellcheck = ru_RU
% !TEX root = vkr.tex

\section{Постановка задачи}
\label{sec:task}

Целью работы является разработка автоматизированной системы парсинга данных с произвольных веб-страниц на основе больших языковых моделей (LLM). Для её выполнения были поставлены следующие задачи:
\begin{enumerate}
    \item Реализовать модуль получения и предварительной обработки веб-страницы, способный обнаруживать и загружать как статические, так и динамически генерируемые (SPA) ресурсы (см. раздел~\ref{subsec:solution1}).
    \item Спроектировать и реализовать стратегии очистки HTML-разметки: «полная» очистка, получающая чистый текст, и «лёгкая» очистка, сохраняющая базовую структуру документа (раздел~\ref{subsec:solution2}).
    \item Разработать механизмы интеграции с LLM для двух режимов работы:
    \begin{itemize}
        \item \emph{Structuring} — прямое извлечение и структурирование данных из очищенного HTML в формат JSON;
        \item \emph{Codegen} — генерация Python-скрипта парсера, который затем исполняется для получения требуемых данных (раздел~\ref{subsec:solution3}).
    \end{itemize}
    \item Реализовать систему кэширования сгенерированных скриптов парсеров и/или результатов структурирования, обеспечивающую повторное использование без повторных обращений к LLM (раздел~\ref{subsec:solution4}).
    \item Разработать пользовательские интерфейсы для удобного доступа к функциональности:
    \begin{itemize}
        \item Gradio-приложение для деплоя в Hugging Face Space;
        \item REST-API на основе FastAPI;
        \item простой веб-frontend (HTML + JavaScript) (раздел~\ref{subsec:solution5}).
    \end{itemize}
    \item Провести валидацию результата работы системы: оценить корректность извлечения данных и измерить производительность (время отклика до/после кэширования) (раздел~\ref{subsec:results}).
\end{enumerate}
